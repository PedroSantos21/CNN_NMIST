{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GA+CNN Notebook Final Version.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Cb6MC4Kuwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam, Adadelta, Adagrad, Adamax, SGD, RMSprop\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "class Classifier:\n",
        "    \n",
        "  def __init__(self, train_digits=None, train_labels=None, validation_digits=None, validation_labels=None,test_digits=None,test_labels=None,verbose=1):\n",
        "    \n",
        "    self.train_digits       = train_digits\n",
        "    self.train_labels       = train_labels \n",
        "    self.test_digits        = test_digits \n",
        "    self.test_labels        = test_labels \n",
        "    self.validation_digits  = validation_digits\n",
        "    self.validation_labels  = validation_labels\n",
        "\n",
        "    self.verbose    = verbose\n",
        "\n",
        "    self.numClasses = 10\n",
        "    \n",
        "    self.height     = self.train_digits.shape[1]\n",
        "    self.width      = self.train_digits.shape[2]\n",
        "    self.channels   = 1\n",
        "\n",
        "    self.model      = None\n",
        "   \n",
        "\n",
        "  def fit(self, test=False, batchSize=64, nbEpochs=10):\n",
        "    if not test:\n",
        "      self.model.fit(self.train_digits, \n",
        "                    self.train_labels, \n",
        "                    batch_size=batchSize, \n",
        "                    epochs=nbEpochs,\n",
        "                    verbose=self.verbose\n",
        "                  )\n",
        "    else:\n",
        "      self.model.fit(self.train_digits, \n",
        "                    self.train_labels, \n",
        "                    batch_size=batchSize, \n",
        "                    epochs=nbEpochs,\n",
        "                    verbose=self.verbose,\n",
        "                    validation_data=(self.validation_digits, self.validation_labels)\n",
        "                  )\n",
        "\n",
        "  def clear(self):\n",
        "    K.clear_session()\n",
        "    # tf.reset_default_graph()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "\n",
        "    \n",
        "  def evaluate(self, test=False, batchSize=64):\n",
        "    if not test:\n",
        "      scores = self.model.evaluate(self.validation_digits, self.validation_labels, batch_size=batchSize, verbose=self.verbose)\n",
        "    else:\n",
        "      scores = self.model.evaluate(self.test_digits, self.test_labels, batch_size=batchSize, verbose=self.verbose)\n",
        "    return dict(zip(self.model.metrics_names, scores))\n",
        "\n",
        "  # TODO: ESTUDAR OS OTIMIZADORES PARA VER SE S√ÉO ADEQUADOS\n",
        "  def checkOptimizer(self, parameters):\n",
        "    opt = None\n",
        "    if parameters['optimizer'] == 'Adam':\n",
        "        opt = Adam(learning_rate=parameters['learningRate'])\n",
        "\n",
        "    if parameters['optimizer'] == 'Sgd':\n",
        "        opt = SGD(learning_rate=parameters['learningRate'])\n",
        "    \n",
        "    if parameters['optimizer'] == 'RMSprop':\n",
        "        opt = RMSprop(learning_rate=parameters['learningRate'])\n",
        "    \n",
        "    if parameters['optimizer'] == 'Adadelta':\n",
        "        opt = Adadelta(learning_rate=parameters['learningRate'])\n",
        "    \n",
        "    if parameters['optimizer'] == 'Adagrad':\n",
        "        opt = Adagrad(learning_rate=parameters['learningRate'])\n",
        "    \n",
        "    if parameters['optimizer'] == 'Adamax':\n",
        "        opt = Adamax(learning_rate=parameters['learningRate'])\n",
        "    \n",
        "    return opt\n",
        "\n",
        "  def configureArchitecture(self, parameters):\n",
        "    self.model = Sequential()\n",
        "    # CONVOLUTIONAL LAYER 1\n",
        "    self.model.add(Conv2D(filters=parameters['cnnSize_1'], kernel_size=(3,3), activation='relu', padding='same', input_shape=(self.height, self.width, self.channels)))\n",
        "    # MAXPOOLING LAYER 1\n",
        "    self.model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    # CONVOLUTIONAL LAYER 2\n",
        "    self.model.add(Conv2D(filters=parameters['cnnSize_2'], kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    # MAXPOOLING LAYER 2\n",
        "    self.model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    # CONVOLUTIONAL LAYER 3\n",
        "    self.model.add(Conv2D(filters=parameters['cnnSize_3'], kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    # MAXPOOLING LAYER 3\n",
        "    self.model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    self.model.add(Flatten())\n",
        "    # FULLY CONNECTED LAYERS\n",
        "    self.model.add(Dense(128, activation='relu'))\n",
        "    # OUTPUT LAYER\n",
        "    self.model.add(Dense(self.numClasses, activation='softmax'))\n",
        "\n",
        "    opt = self.checkOptimizer(parameters)\n",
        "\n",
        "    self.model.compile( loss='categorical_crossentropy',\n",
        "                        optimizer=opt,\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdx8UKbSK7yD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from random import random, randint, uniform, choice, choices, sample\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "import sys\n",
        "\n",
        "\n",
        "class GeneticAlgorithm:\n",
        "\n",
        "    def __init__(self,\n",
        "        parameters,\n",
        "        fitnessFunction,\n",
        "        population_size,\n",
        "        generations,\n",
        "        elitism         = 0.1,\n",
        "        crossover_rate  = 0.8,\n",
        "        crossoverPoint  = None,\n",
        "        mutation_rate   = 0.25,\n",
        "        random_selection_rate = 0.01\n",
        "    ):\n",
        "        self.elitism = elitism\n",
        "        self.generations = generations\n",
        "        self.populationSize = population_size\n",
        "        self.crossoverRate = crossover_rate\n",
        "        self.mutationRate  = mutation_rate\n",
        "        self.randoSelectionRate = random_selection_rate\n",
        "        \n",
        "        self.parametersRange = list(parameters.values())\n",
        "        self.fitnessFunction = fitnessFunction\n",
        "        \n",
        "        # CROSSOVER\n",
        "        self.crossoverPoint = int(len(parameters)/2) if crossoverPoint == None else crossoverPoint\n",
        "\n",
        "        # AUX\n",
        "        self.precision = 7\n",
        "\n",
        "        # self.population = self.createPopulation()\n",
        "    \n",
        "\n",
        "    # POPULATIONAL SECTION\n",
        "    def createIndividual(self):\n",
        "        '''\n",
        "        Individual is represented as a possible solution \n",
        "        to the problem.\n",
        "\n",
        "        In this case a solution is an array with values of\n",
        "        the selected hyperparameters.\n",
        "\n",
        "        A probability distribution (random, gaussian, uniform) is the best way to generate\n",
        "        values inside a range of possible values\n",
        "        '''\n",
        "        return [round(uniform(*parameter), 3) if type(parameter) == tuple else choice(parameter)\n",
        "            for parameter in self.parametersRange]\n",
        "    \n",
        "    def individualFormat(self, individual):\n",
        "        return tuple(individual)\n",
        "    \n",
        "    def createPopulation(self):\n",
        "        '''\n",
        "        Create an initial random population according with the\n",
        "        parameters of the problem and its valid values\n",
        "        '''\n",
        "        print(\"Creating initial random population...\")\n",
        "        population = []\n",
        "        while len(population) < self.populationSize:\n",
        "            ind = self.createIndividual()\n",
        "            print(ind)\n",
        "            population.append(ind)\n",
        "        return population\n",
        "\n",
        "    #   FITNESS SECTION\n",
        "    def fitness(self, individual):\n",
        "        '''\n",
        "        function fitness = evaluate_individual\n",
        "        '''\n",
        "        ind = self.individualFormat(individual)\n",
        "        return self.fitnessFunction(ind)\n",
        "\n",
        "\n",
        "    def sortByFitness(self, population):\n",
        "        scores = [self.fitness(individual) for individual in tqdm(population, desc=\"Measuring Population Fitness\", file=sys.stdout)]\n",
        "        return [x for _, x in sorted(zip(scores, population), key=lambda p: p[0], reverse=True)]\n",
        "\n",
        "    def populationFitness(self, population):\n",
        "        return [self.fitness(individual) for individual in tqdm(population, desc=\"Measuring Population Fitness\", file=sys.stdout)]    \n",
        "    \n",
        "    def orderPopulation(self, scores, population):\n",
        "        self.scores, self.population = [list(t) for t in zip(*sorted(zip(scores, population)))]   \n",
        "\n",
        "\n",
        "    def grade(self, list_fit=None):\n",
        "        '''\n",
        "        Find minimum fitness for a population.\n",
        "        '''\n",
        "        if not list_fit:\n",
        "            list_fit = self.scores\n",
        "        try:\n",
        "            return np.nanmin([fit for fit in self.scores])\n",
        "        except:\n",
        "            return np.nan\n",
        "    \n",
        "    # REPRODUCTION SECTION\n",
        "    def crossover(self, individual1, individual2):\n",
        "\n",
        "        child1 = individual1.copy()\n",
        "        child2 = individual2.copy()\n",
        "\n",
        "        if np.random.uniform(0,1) < self.crossoverRate:\n",
        "            child1 = individual1[:self.crossoverPoint] + individual2[self.crossoverPoint:]\n",
        "            child2 = individual2[:self.crossoverPoint] + individual1[self.crossoverPoint:]\n",
        "\n",
        "        return child1, child2\n",
        "\n",
        "\n",
        "    # MUTATION SECTION\n",
        "    def mutation(self, individual):\n",
        "        if np.random.uniform(0,1) < self.mutationRate:\n",
        "            locus = randint(0, len(individual)-1)\n",
        "            parameter = self.parametersRange[locus]\n",
        "            individual[locus] = uniform(*parameter) if type(parameter) == tuple else choice(parameter)\n",
        "\n",
        "\n",
        "\n",
        "    # GENERATIONAL SECTION\n",
        "    def evolve(self):\n",
        "\n",
        "        # ELITISMO\n",
        "        elitismSize = int(self.populationSize*self.elitism)\n",
        "        # orderedPop = self.sortByFitness(population)\n",
        "        newGeneration = [ind for ind in tqdm(self.population[:elitismSize], desc=\"Applying Elitism\", file=sys.stdout)]\n",
        "\n",
        "        while len(newGeneration) < self.populationSize:\n",
        "            \n",
        "            # RANDOM SELECTION (DIVERSITY)\n",
        "            for individual in tqdm(self.population[elitismSize:], desc=\"Random Selection\", file=sys.stdout):\n",
        "                if np.random.uniform(0,1) < self.randoSelectionRate:\n",
        "                    newGeneration.append(individual)\n",
        "        \n",
        "            # RANDOM MUTATION (DIVERSITY)\n",
        "            for individual in tqdm(self.population[elitismSize:], desc=\"Random Mutation\", file=sys.stdout):\n",
        "                self.mutation(individual)\n",
        "                newGeneration.append(individual)\n",
        "\n",
        "            # CROSSOVER\n",
        "            ind1, ind2 = sample(self.population, 2)\n",
        "\n",
        "            child1, child2 = self.crossover(ind1, ind2)\n",
        "\n",
        "            if np.random.uniform(0,1) < self.mutationRate:\n",
        "                randomSelection = choice([child1, child2])\n",
        "                self.mutation(randomSelection)\n",
        "                newGeneration.append(randomSelection)            \n",
        "            newGeneration.append(child1)\n",
        "            newGeneration.append(child2)\n",
        "\n",
        "        # EVALUATE POPULATION\n",
        "        generationScores = self.populationFitness(newGeneration)\n",
        "        generationbestFitness = self.grade(generationScores) \n",
        "\n",
        "        print(\"Best fitness of this generation:\", generationbestFitness)\n",
        "\n",
        "        self.orderPopulation(generationScores, newGeneration)\n",
        "        self.bestFitness = generationbestFitness\n",
        "\n",
        "        \n",
        "\n",
        "    def populationInfo(self, population):\n",
        "        pass\n",
        "        \n",
        "\n",
        "    def run(self):\n",
        "        \n",
        "        counter = 0\n",
        "        # CREATE INITIAL RANDOM POPULATION\n",
        "        self.population = self.createPopulation()\n",
        "\n",
        "        # EVALUATE INITIAL POPULATION\n",
        "        self.scores = self.populationFitness(self.population)\n",
        "        self.bestFitness = self.grade() \n",
        "        print(\"Initial best fitness:\", self.bestFitness)\n",
        "        \n",
        "        # ORGANIZING POPULATION BY FITNESS\n",
        "        self.orderPopulation(self.scores, self.population)\n",
        "        \n",
        "        while counter < self.generations:\n",
        "            print(f\"\\n  Running iteration {(counter+1)}/{self.generations}\")\n",
        "\n",
        "            self.evolve()\n",
        "\n",
        "            counter += 1\n",
        "        \n",
        "        return self.bestFitness, self.population\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7mimiFpLOE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets.mnist import load_data\n",
        "import matplotlib.pyplot as plt\n",
        "from math import *\n",
        "\n",
        "\n",
        "# AUXILIARY FUNCTIONS\n",
        "def convertPow2(num):\n",
        "  '''\n",
        "    Convert num to the closest power of 2\n",
        "  '''\n",
        "  return int(pow(2, ceil(log2(abs(num)))))\n",
        "\n",
        "def convertRange(num, bounds):\n",
        "  '''\n",
        "    Clip number to the bounds\n",
        "  '''\n",
        "  num = round(abs(num), num_digits)\n",
        "  return np.clip(num, *bounds)\n",
        "\n",
        "def load_dataset():\n",
        "        (train_digits, train_labels), (test_digits, test_labels) = load_data()\n",
        "        return (train_digits, train_labels), (test_digits, test_labels)\n",
        "\n",
        "def load_dataset_with_validation(rate=0.10):\n",
        "    \"\"\"\n",
        "    Load dataset setting apart some validation data\n",
        "    @args:\n",
        "        - rate: Percentage of training data to validation\n",
        "    \"\"\"\n",
        "\n",
        "    (train_digits, train_labels), (test_digits, test_labels) = load_dataset()\n",
        "    \n",
        "    # RESHAPE DATA\n",
        "    train_data = reshapeDataset(train_digits)\n",
        "    test_data  = reshapeDataset(test_digits)\n",
        "\n",
        "    # RESCALE DATA\n",
        "    train_data = rescaleDataset(train_data)\n",
        "    test_data  = rescaleDataset(test_data)\n",
        "\n",
        "    # ONE-HOT ENCODING\n",
        "    train_labels_cat = encodingDataset(train_labels)\n",
        "    test_labels_cat  = encodingDataset(test_labels)\n",
        "\n",
        "    # SHUFFLE THE TRAINING DATASET\n",
        "    for _ in range(5):\n",
        "        indexes = np.random.permutation(len(train_data))\n",
        "    \n",
        "    train_data          = train_data[indexes]\n",
        "    train_labels_cat    =  train_labels_cat[indexes]\n",
        "\n",
        "    splitPnt = int(rate*len(train_data))\n",
        "\n",
        "    validation_data         = train_data[:splitPnt,:]\n",
        "    validation_labels_cat   = train_labels_cat[:splitPnt,:]\n",
        "\n",
        "    train_data2         = train_data[splitPnt:,:]\n",
        "    train_labels_cat2   = train_labels_cat[splitPnt:,:]\n",
        "\n",
        "    return train_data2, train_labels_cat2, test_data, test_labels_cat, validation_data, validation_labels_cat\n",
        "  \n",
        "def reshapeDataset(data):\n",
        "    \"\"\"\n",
        "    Reshaping data to CNN standard\n",
        "    \"\"\"\n",
        "    height      = data.shape[1]\n",
        "    width       = data.shape[2]\n",
        "    channels    = 1\n",
        "\n",
        "    return np.reshape(data, (data.shape[0], height, width, channels))\n",
        "\n",
        "def rescaleDataset(data):\n",
        "    \"\"\"\n",
        "    Rescaling data\n",
        "    \"\"\"\n",
        "    return data.astype('float32')/255\n",
        "\n",
        "def encodingDataset(dataLabels, numClasses=10):\n",
        "    \"\"\"\n",
        "    ONE-HOT ENCODING\n",
        "    @args:\n",
        "        - dataLabels\n",
        "        - numClasses\n",
        "    \n",
        "    @output:\n",
        "        - List of classes\n",
        "    \"\"\"    \n",
        "    return to_categorical(dataLabels, numClasses)\n",
        "\n",
        "def showRandomImages(data, labels):\n",
        "    \"\"\"\n",
        "    Exhibit 14 random samples from dataset\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(123)\n",
        "\n",
        "    rand_14 = np.random.randint(0, data.shape[0], 14)\n",
        "    sample_digits = data[rand_14]\n",
        "    sample_labels = labels[rand_14]\n",
        "\n",
        "    num_rows, num_cols = 2,7\n",
        "\n",
        "    f, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),\n",
        "                        gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n",
        "                        squeeze=True)\n",
        "\n",
        "    for r in range(num_rows):\n",
        "        for c in range(num_cols):\n",
        "            image_index = r * 7 + c\n",
        "            ax[r,c].axis(\"off\")\n",
        "            ax[r,c].imshow(sample_digits[image_index], cmap='gray')\n",
        "            ax[r,c].set_title('No. %d' % sample_labels[image_index])\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm9sxWIfLBup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80599a1f-b971-4c39-cdad-e5567c4efb23"
      },
      "source": [
        "import sys\n",
        "# from utils import *\n",
        "# from classifier import Classifier\n",
        "# from evolutionaryAlgorithms import GeneticAlgorithm as GA\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "from os import makedirs\n",
        "import traceback\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from getpass import getpass\n",
        "import smtplib\n",
        "import logging\n",
        "from time import time\n",
        "\n",
        "\n",
        "\n",
        "def run(**kwargs):\n",
        "    algorithm = kwargs.get('algorithm')\n",
        "    dataset = kwargs.get('dataset')\n",
        "\n",
        "    if kwargs.get('algorithm') == 'GA':\n",
        "        parameters = kwargs.get('parameters')\n",
        "        popSize = kwargs.get('population_size')\n",
        "        generations = kwargs.get('generations')\n",
        "\n",
        "        # evolver = GA(fitness, parameters, popSize, generations, history)\n",
        "        evolver = GeneticAlgorithm(parameters=parameters, fitnessFunction=fitness, population_size=popSize, generations=generations)\n",
        "    else:\n",
        "        pass\n",
        "        \n",
        "    best, population= evolver.run()\n",
        "    print(\"Best Solution after \"+str(generations)+\" generations...\")\n",
        "    print(\n",
        "        \"Learning Rate: \"+str(population[0][0]) +\n",
        "        \"\\n Optimizer: \" + str(population[0][1]) +\n",
        "        \"\\n cnnSize_1: \"+str(population[0][2]) +\n",
        "        \"\\n cnnSize_2: \" +str(population[0][3]) +\n",
        "        \"\\n cnnSize_3: \" +str(population[0][4])\n",
        "    )\n",
        "    print(\"Fitness (loss)\" +str(best))\n",
        "\n",
        "    # # create results dir\n",
        "    # timestamp = datetime.now().strftime('%d-%m-%Y_%H-%M-%S')\n",
        "    # path = f\"{algorithm}/results_NMIST_{timestamp}\"\n",
        "    # makedirs(path)\n",
        "        \n",
        "    # with open(f\"{path}/{algorithm}_results.txt\", \"w+\") as f:\n",
        "\n",
        "    #     results = []\n",
        "    #     loss = []\n",
        "\n",
        "\n",
        "    #     for i in range(generations):\n",
        "    #         print(f\"\\nRunning execution {(i+1)}/{generations}\")\n",
        "    #         # Run Evolver\n",
        "    #         print('BEST GENE', best['gene'])\n",
        "    #         # Calculate loss\n",
        "    #         gen_loss = evolver.fitness(best['gene'], test=True, batch_size=batch_size, epochs=epochs)\n",
        "    #         print('gen_loss', gen_loss)\n",
        "    #         loss.append(gen_loss)\n",
        "    #         # Store results\n",
        "    #         results.append({\n",
        "    #             'best': best,\n",
        "    #             'gen_loss': gen_loss,\n",
        "    #             'hist': hist, \n",
        "    #             'pop': evolver.pop, \n",
        "    #             'fit': evolver.fit, \n",
        "    #             'history': evolver.history\n",
        "    #         })\n",
        "    #     f.write(str(results))\n",
        "    \n",
        "    # # Calculate stats\n",
        "    # mean = np.nanmean(loss)\n",
        "    # std = np.nanstd(loss)\n",
        "    \n",
        "    # # Store stats         \n",
        "    # with open(f\"{path}/report.txt\", \"w+\") as f:\n",
        "    #   f.write(f\"{algorithm} - Mean: {mean} | Std: {std}\\n\")\n",
        "      \n",
        "    # print(\"Success\")\n",
        "    # print(str(loss))\n",
        "    # print(str(results))\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    pass\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # GLOBAL GA PARAMETERS  \n",
        "    GENERATIONS             = 2\n",
        "    POPULATION_SIZE         = 4\n",
        "    MUTATION_RATE           = 0.4\n",
        "    CROSSOVER_RATE          = 0.8\n",
        "\n",
        "    # GLOBAL CNN PARAMETERS\n",
        "    EPOCHS                  = 2\n",
        "    BATCH_SIZE              = 256\n",
        "\n",
        "\n",
        "    # Hiperparametros:\n",
        "    # - Learning rate\n",
        "    # - Funcao de otimizacao\n",
        "    # - Tamanho camada 1\n",
        "    # - Tamanho camada 2\n",
        "    # - Tamanho camada 3\n",
        "\n",
        "    # Fitness:\n",
        "    # - loss\n",
        "    # - accuracy\n",
        "\n",
        "    # Intervalo do tamanho da camada [2, 1024]\n",
        "\n",
        "    parameters = {\n",
        "        'learningRate': (0.001, 0.1),\n",
        "        'optimizer': ['Adam', 'Sgd', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax'],\n",
        "        'cnnSize_1': [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n",
        "        'cnnSize_2': [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n",
        "        'cnnSize_3': [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
        "    }\n",
        "\n",
        "    normParam = {\n",
        "        'cnnSize_1': convertPow2,\n",
        "        'cnnSize_2': convertPow2,\n",
        "        'cnnSize_3': convertPow2\n",
        "    }\n",
        "\n",
        "    train_data, train_labels_cat, \\\n",
        "    test_data, test_labels_cat, \\\n",
        "    validation_data, validation_labels_cat = load_dataset_with_validation()\n",
        "\n",
        "    # Instantiate CNN Clssifier with the MNIST dataset\n",
        "    cnn = Classifier(\n",
        "        train_digits        =train_data,\n",
        "        train_labels        =train_labels_cat,\n",
        "        validation_digits   =validation_data,\n",
        "        validation_labels   =validation_labels_cat,\n",
        "        test_digits         =test_data,\n",
        "        test_labels         =test_labels_cat,\n",
        "        verbose             =1)\n",
        "\n",
        "    def fitness(individual, test=False):\n",
        "        cnn.clear()\n",
        "\n",
        "        cnn.configureArchitecture(dict(zip(parameters.keys(), individual)) if not isinstance(individual, dict) else individual)\n",
        "\n",
        "        cnn.fit(batchSize=BATCH_SIZE, nbEpochs=EPOCHS)\n",
        "\n",
        "        results = cnn.evaluate(test)\n",
        "        return results['loss']\n",
        "\n",
        "    run(algorithm='GA', dataset='NMIST',fitness=fitness, parameters=parameters, population_size=POPULATION_SIZE, generations=GENERATIONS)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating initial random population...\n",
            "[0.036, 'RMSprop', 4, 8, 1024]\n",
            "[0.092, 'Adadelta', 2, 2, 1024]\n",
            "[0.003, 'RMSprop', 16, 16, 16]\n",
            "[0.046, 'RMSprop', 128, 64, 128]\n",
            "\n",
            "Measuring Population Fitness:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 3s 59us/step - loss: 4.2537 - accuracy: 0.1061\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 3s 48us/step - loss: 2.3030 - accuracy: 0.1103\n",
            "6000/6000 [==============================] - 0s 57us/step\n",
            "\n",
            "Measuring Population Fitness:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:06<00:19,  6.55s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 3s 55us/step - loss: 1.2330 - accuracy: 0.6455\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 2s 45us/step - loss: 0.3484 - accuracy: 0.8911\n",
            "6000/6000 [==============================] - 0s 59us/step\n",
            "\n",
            "Measuring Population Fitness:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:12<00:12,  6.50s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 1s 25us/step - loss: 0.3639 - accuracy: 0.8851\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 1s 20us/step - loss: 0.0984 - accuracy: 0.9688\n",
            "6000/6000 [==============================] - 0s 50us/step\n",
            "\n",
            "Measuring Population Fitness:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:16<00:05,  5.50s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 4s 75us/step - loss: 224.3352 - accuracy: 0.6024\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 3s 65us/step - loss: 0.3806 - accuracy: 0.8955\n",
            "6000/6000 [==============================] - 0s 66us/step\n",
            "\n",
            "Measuring Population Fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:24<00:00,  6.13s/it]\n",
            "Initial best fitness: 0.09661066901683807\n",
            "\n",
            "  Running iteration 1/2\n",
            "\n",
            "Applying Elitism: 0it [00:00, ?it/s]\n",
            "\n",
            "Random Selection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 34169.48it/s]\n",
            "\n",
            "Random Mutation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 31359.28it/s]\n",
            "\n",
            "Measuring Population Fitness:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 3s 51us/step - loss: 33.9154 - accuracy: 0.7625\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 3s 49us/step - loss: 0.3402 - accuracy: 0.9083\n",
            "6000/6000 [==============================] - 0s 46us/step\n",
            "\n",
            "Measuring Population Fitness:  12%|‚ñà‚ñé        | 1/8 [00:06<00:43,  6.28s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 1s 21us/step - loss: 0.3696 - accuracy: 0.8813\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 1s 21us/step - loss: 0.0974 - accuracy: 0.9696\n",
            "6000/6000 [==============================] - 0s 41us/step\n",
            "\n",
            "Measuring Population Fitness:  25%|‚ñà‚ñà‚ñå       | 2/8 [00:09<00:31,  5.31s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 4s 67us/step - loss: 406.2234 - accuracy: 0.1044\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 4s 65us/step - loss: 2.3033 - accuracy: 0.1053\n",
            "6000/6000 [==============================] - 0s 52us/step\n",
            "\n",
            "Measuring Population Fitness:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [00:17<00:30,  6.10s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 3s 49us/step - loss: 1.6308 - accuracy: 0.5633\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 2s 46us/step - loss: 0.2707 - accuracy: 0.9177\n",
            "6000/6000 [==============================] - 0s 48us/step\n",
            "\n",
            "Measuring Population Fitness:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [00:23<00:24,  6.08s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 3s 50us/step - loss: 3.5619 - accuracy: 0.1055\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 3s 49us/step - loss: 2.3028 - accuracy: 0.1098\n",
            "6000/6000 [==============================] - 0s 44us/step\n",
            "\n",
            "Measuring Population Fitness:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [00:29<00:18,  6.07s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 4s 70us/step - loss: 1.0838 - accuracy: 0.6865\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 4s 69us/step - loss: 0.2123 - accuracy: 0.9347\n",
            "6000/6000 [==============================] - 0s 53us/step\n",
            "\n",
            "Measuring Population Fitness:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [00:37<00:13,  6.77s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 2s 45us/step - loss: 5.9536 - accuracy: 0.1072\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 2s 44us/step - loss: 2.3036 - accuracy: 0.1064\n",
            "6000/6000 [==============================] - 0s 48us/step\n",
            "\n",
            "Measuring Population Fitness:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [00:43<00:06,  6.40s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 4s 71us/step - loss: 1.0226 - accuracy: 0.7113\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 4s 68us/step - loss: 0.1919 - accuracy: 0.9429\n",
            "6000/6000 [==============================] - 0s 53us/step\n",
            "\n",
            "Measuring Population Fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:51<00:00,  6.49s/it]\n",
            "Best fitness of this generation: 0.09661066901683807\n",
            "\n",
            "  Running iteration 2/2\n",
            "\n",
            "Applying Elitism: 0it [00:00, ?it/s]\n",
            "\n",
            "Random Selection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 61908.55it/s]\n",
            "\n",
            "Random Mutation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 40184.95it/s]\n",
            "\n",
            "Measuring Population Fitness:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 1s 22us/step - loss: 0.3595 - accuracy: 0.8842\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 1s 20us/step - loss: 0.0885 - accuracy: 0.9719\n",
            "6000/6000 [==============================] - 0s 38us/step\n",
            "\n",
            "Measuring Population Fitness:   9%|‚ñâ         | 1/11 [00:02<00:29,  2.96s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 3s 58us/step - loss: 1.3690 - accuracy: 0.5809\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 3s 52us/step - loss: 0.3384 - accuracy: 0.8930\n",
            "6000/6000 [==============================] - 0s 50us/step\n",
            "\n",
            "Measuring Population Fitness:  18%|‚ñà‚ñä        | 2/11 [00:09<00:37,  4.13s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 3s 55us/step - loss: 1.4438 - accuracy: 0.5117\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 3s 52us/step - loss: 0.3593 - accuracy: 0.8861\n",
            "6000/6000 [==============================] - 0s 48us/step\n",
            "\n",
            "Measuring Population Fitness:  27%|‚ñà‚ñà‚ñã       | 3/11 [00:16<00:39,  4.90s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 1s 21us/step - loss: 2.1720 - accuracy: 0.3134\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 1s 18us/step - loss: 0.8956 - accuracy: 0.7112\n",
            "6000/6000 [==============================] - 0s 40us/step\n",
            "\n",
            "Measuring Population Fitness:  36%|‚ñà‚ñà‚ñà‚ñã      | 4/11 [00:19<00:30,  4.31s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 3s 51us/step - loss: 1.0748 - accuracy: 0.8112\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 3s 50us/step - loss: 0.1125 - accuracy: 0.9656\n",
            "6000/6000 [==============================] - 0s 41us/step\n",
            "\n",
            "Measuring Population Fitness:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5/11 [00:25<00:29,  4.87s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 2s 45us/step - loss: 0.5767 - accuracy: 0.8067\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 2s 43us/step - loss: 0.1569 - accuracy: 0.9496\n",
            "6000/6000 [==============================] - 0s 43us/step\n",
            "\n",
            "Measuring Population Fitness:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 6/11 [00:31<00:25,  5.12s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 3s 52us/step - loss: 1.2662 - accuracy: 0.8181\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 3s 49us/step - loss: 0.1155 - accuracy: 0.9649\n",
            "6000/6000 [==============================] - 0s 47us/step\n",
            "\n",
            "Measuring Population Fitness:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 7/11 [00:37<00:21,  5.45s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 4s 67us/step - loss: 174.5540 - accuracy: 0.1070\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 4s 65us/step - loss: 2.3035 - accuracy: 0.1069\n",
            "6000/6000 [==============================] - 0s 51us/step\n",
            "\n",
            "Measuring Population Fitness:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 8/11 [00:45<00:18,  6.20s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 4s 67us/step - loss: 5.9312 - accuracy: 0.1106\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 4s 65us/step - loss: 2.3019 - accuracy: 0.1109\n",
            "6000/6000 [==============================] - 0s 50us/step\n",
            "\n",
            "Measuring Population Fitness:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 9/11 [00:53<00:13,  6.72s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 4s 68us/step - loss: 2.8479 - accuracy: 0.8403\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 4s 66us/step - loss: 0.0962 - accuracy: 0.9724\n",
            "6000/6000 [==============================] - 0s 54us/step\n",
            "\n",
            "Measuring Population Fitness:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 10/11 [01:01<00:07,  7.10s/it]\u001b[AEpoch 1/2\n",
            "54000/54000 [==============================] - 3s 51us/step - loss: 34.4767 - accuracy: 0.1131\n",
            "Epoch 2/2\n",
            "54000/54000 [==============================] - 3s 48us/step - loss: 2.3034 - accuracy: 0.1067\n",
            "6000/6000 [==============================] - 0s 45us/step\n",
            "\n",
            "Measuring Population Fitness: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [01:07<00:00,  6.14s/it]\n",
            "Best fitness of this generation: 0.06691301063696543\n",
            "Best Solution after 2 generations...\n",
            "Learning Rate: 0.003Optimizer: RMSpropcnnSize_1: 16cnnSize_2: 16cnnSize_3: 16\n",
            "Fitness (loss)0.06691301063696543\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}